# Pipeline Datanex - Wiki Processor

Pipeline para descargar, limpiar y procesar la wiki de Datanex (base de datos del Hospital ClÃ­nic) y generar un archivo de contexto optimizado para GitHub Copilot.

## ğŸ“‹ DescripciÃ³n

Este proyecto descarga todas las pÃ¡ginas de la wiki de Datanex desde GitLab, las procesa, filtra las pÃ¡ginas relevantes, las convierte a Markdown y genera un archivo unificado (`vibe_SQL_copilot.txt`) que combina un prompt personalizado con toda la documentaciÃ³n de la base de datos. Este archivo estÃ¡ diseÃ±ado para ser usado como contexto en GitHub Copilot para generar queries SQL de alta calidad.

## ğŸš€ CaracterÃ­sticas

- **Descarga automÃ¡tica**: Descarga recursiva de pÃ¡ginas wiki desde GitLab
- **Filtrado inteligente**: Filtra solo las pÃ¡ginas Ãºtiles segÃºn un archivo de configuraciÃ³n
- **ConversiÃ³n a Markdown**: Convierte HTML a Markdown preservando tablas y estructura
- **Limpieza automÃ¡tica**: Elimina secciones no relevantes y normaliza el formato
- **UnificaciÃ³n**: Combina todos los documentos en un solo archivo optimizado
- **Procesamiento de diccionarios**: Convierte diccionarios CSV a Markdown con optimizaciÃ³n de tamaÃ±o
- **CompactaciÃ³n inteligente**: Reduce el tamaÃ±o eliminando prefijos comunes y texto redundante
- **Pipeline modular**: Cada paso es independiente y testeable

## ğŸ“ Estructura del Proyecto

```
pipeline_datanex/
â”œâ”€â”€ src/                          # CÃ³digo fuente
â”‚   â”œâ”€â”€ download_wiki.py          # Descarga de pÃ¡ginas wiki
â”‚   â”œâ”€â”€ extract_text.py           # ExtracciÃ³n a Markdown
â”‚   â”œâ”€â”€ unify_markdown.py         # UnificaciÃ³n de markdowns
â”‚   â”œâ”€â”€ unify_dictionaries.py     # UnificaciÃ³n de diccionarios CSV
â”‚   â””â”€â”€ create_final_output.py    # CreaciÃ³n del archivo final
â”œâ”€â”€ test/                         # Tests/Pasos del pipeline
â”‚   â”œâ”€â”€ test_download_wiki.py
â”‚   â”œâ”€â”€ test_filter_useful_pages.py
â”‚   â”œâ”€â”€ test_extract_text.py
â”‚   â”œâ”€â”€ test_download_linked_pages.py
â”‚   â”œâ”€â”€ test_unify_markdown.py
â”‚   â”œâ”€â”€ test_unify_dictionaries.py
â”‚   â”œâ”€â”€ test_create_final_output.py
â”‚   â””â”€â”€ run_all_tests.py          # Ejecuta todo el pipeline
â”œâ”€â”€ dicc/                         # Diccionarios CSV
â”‚   â”œâ”€â”€ dic_diagnostic.csv        # Diccionario de diagnÃ³sticos
â”‚   â”œâ”€â”€ dic_lab.csv               # Diccionario de laboratorio
â”‚   â””â”€â”€ dictionaries_unified.md   # Diccionarios unificados
â”œâ”€â”€ data/                         # Datos procesados (ignorado en git)
â”‚   â”œâ”€â”€ wiki_html/                # HTML descargado
â”‚   â”œâ”€â”€ wiki_work_html/           # HTML filtrado (pÃ¡ginas Ãºtiles)
â”‚   â”œâ”€â”€ wiki_markdown/            # Markdowns generados
â”‚   â””â”€â”€ wiki_unified.md            # Markdown unificado
â”œâ”€â”€ main.py                       # Script principal
â”œâ”€â”€ ejecutar_pipeline.bat         # Script batch para ejecutar en Windows
â”œâ”€â”€ ejecutar_pipeline.sh          # Script bash para ejecutar en Linux/Mac
â”œâ”€â”€ prompt.txt                    # Prompt para Copilot
â”œâ”€â”€ pags_descarte.txt             # Lista de pÃ¡ginas a descartar/excluir
â””â”€â”€ vibe_SQL_copilot.txt          # Archivo final generado
```

## ğŸ”§ InstalaciÃ³n

### Requisitos

- Python 3.8 o superior
- pip

### Pasos

1. **Clonar el repositorio**:
```bash
git clone https://github.com/ramsestein/vibe_SQL_Datanex.git
cd vibe_SQL_Datanex
```

2. **Crear entorno virtual** (recomendado):
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

## ğŸ“¦ Dependencias

- `requests` - Para descargar pÃ¡ginas web
- `beautifulsoup4` - Para parsear HTML
- `markdownify` - Para convertir HTML a Markdown

## ğŸ¯ Uso

### Ejecutar el pipeline completo

**Windows (mÃ¡s fÃ¡cil)**:
```bash
ejecutar_pipeline.bat
```

**Linux/Mac (mÃ¡s fÃ¡cil)**:
```bash
./ejecutar_pipeline.sh
```

**Desde la lÃ­nea de comandos**:
```bash
python main.py
```

Ambos scripts (`ejecutar_pipeline.bat` y `ejecutar_pipeline.sh`) incluyen:
- MenÃº interactivo para gestionar la lista de pÃ¡ginas a excluir
- CreaciÃ³n automÃ¡tica del entorno virtual si no existe
- VerificaciÃ³n e instalaciÃ³n automÃ¡tica de dependencias
- GestiÃ³n de pÃ¡ginas: ver, agregar o quitar pÃ¡ginas de la lista de exclusiÃ³n
- **Push automÃ¡tico**: Al finalizar el pipeline, sube automÃ¡ticamente el archivo `vibe_SQL_copilot.txt` al repositorio [vibe_query_DataNex](https://github.com/ramsestein/vibe_query_DataNex)

Este comando ejecuta todos los pasos del pipeline en secuencia:

1. **Descarga del Overview**: Descarga la pÃ¡gina principal de la wiki
2. **ExtracciÃ³n a Markdown**: Convierte el Overview a Markdown
3. **Descarga de pÃ¡ginas referenciadas**: Descarga todas las pÃ¡ginas enlazadas en el Overview
4. **Filtrado**: Excluye las pÃ¡ginas listadas en `pags_descarte.txt` (procesa todas las demÃ¡s)
5. **ExtracciÃ³n a Markdown**: Convierte las pÃ¡ginas Ãºtiles a Markdown
6. **UnificaciÃ³n de markdowns**: Combina todos los markdowns de la wiki en un solo archivo
7. **UnificaciÃ³n de diccionarios**: Convierte diccionarios CSV a Markdown optimizado
8. **Archivo final**: Combina `prompt.txt` + `wiki_unified.md` + `dictionaries_unified.md` â†’ `vibe_SQL_copilot.txt`

### Ejecutar pasos individuales

Cada paso puede ejecutarse de forma independiente usando los scripts de test:

```bash
# Paso 1: Descarga
python test/test_download_wiki.py

# Paso 2: Filtrado
python test/test_filter_useful_pages.py

# Paso 3: ExtracciÃ³n
python test/test_extract_text.py

# Paso 4: Descarga de referencias
python test/test_download_linked_pages.py

# Paso 5: UnificaciÃ³n de markdowns
python test/test_unify_markdown.py

# Paso 6: UnificaciÃ³n de diccionarios
python test/test_unify_dictionaries.py

# Paso 7: Archivo final
python test/test_create_final_output.py
```

### Ejecutar todos los pasos en secuencia

```bash
python test/run_all_tests.py
```

## âš™ï¸ ConfiguraciÃ³n

### Archivo `pags_descarte.txt`

Este archivo define quÃ© pÃ¡ginas de la wiki se **EXCLUIRÃN** (descartarÃ¡n) del prompt final. Cada lÃ­nea debe contener el nombre de la pÃ¡gina a excluir (sin extensiÃ³n):

```
News
FAQs
Access-Instructions
...
```

**âš ï¸ Importante**: 
- La pÃ¡gina `Overview` **siempre se incluirÃ¡**, incluso si estÃ¡ en esta lista de exclusiÃ³n, ya que es necesaria para descargar las pÃ¡ginas referenciadas.
- Si el archivo estÃ¡ vacÃ­o o no existe, se procesarÃ¡n **todas** las pÃ¡ginas disponibles.
- Esta es una lista de **exclusiÃ³n**, no de inclusiÃ³n.

### Archivo `prompt.txt`

Este archivo contiene el prompt que se incluirÃ¡ al inicio del archivo final. Define el comportamiento esperado de Copilot al usar el contexto. Debe contener las secciones `### CONTEXTO ###` y `### DICCIONARIOS ###` donde se insertarÃ¡ el contenido correspondiente.

### Carpeta `dicc/`

Contiene los diccionarios CSV que se procesarÃ¡n:
- `dic_diagnostic.csv`: Diccionario de diagnÃ³sticos con cÃ³digos y descripciones
- `dic_lab.csv`: Diccionario de laboratorio con cÃ³digos y descripciones

**âš ï¸ ConfiguraciÃ³n de columnas**: Para que el sistema procese correctamente los CSV, **debes renombrar manualmente** las columnas en tus archivos CSV para que terminen en `_ref` y `_descr`. Por ejemplo:
- Columna de cÃ³digos: `codigo_ref`, `id_ref`, `diagnostic_ref`, etc.
- Columna de descripciones: `descripcion_descr`, `nombre_descr`, `diagnostic_descr`, etc.

El sistema buscarÃ¡ automÃ¡ticamente columnas que terminen en `*_ref` y `*_descr` en todos los archivos CSV de esta carpeta.

Los diccionarios se procesan automÃ¡ticamente y se optimizan para reducir el tamaÃ±o del archivo final.

## ğŸ“Š Pipeline Detallado

### Paso 1: Descarga del Overview
- Descarga la pÃ¡gina principal de la wiki
- Guarda el HTML en `data/wiki_html/`

### Paso 2: ExtracciÃ³n a Markdown del Overview
- Extrae el contenido principal del HTML
- Convierte a Markdown preservando tablas
- Guarda en `data/wiki_markdown/Overview.md`

### Paso 3: Descarga de pÃ¡ginas referenciadas
- Lee el Overview.md y extrae todos los enlaces a otras pÃ¡ginas wiki
- Descarga cada pÃ¡gina referenciada
- Guarda en `data/wiki_html/`

### Paso 4: Filtrado de pÃ¡ginas Ãºtiles
- Lee `pags_descarte.txt` (lista de pÃ¡ginas a EXCLUIR/DESCARTAR)
- Copia TODAS las pÃ¡ginas de `data/wiki_html/` EXCEPTO las listadas en `pags_descarte.txt`
- Siempre incluye `Overview` aunque estÃ© en la lista de exclusiÃ³n
- Guarda las pÃ¡ginas filtradas en `data/wiki_work_html/`

### Paso 5: ExtracciÃ³n a Markdown de pÃ¡ginas Ãºtiles
- Convierte todas las pÃ¡ginas filtradas a Markdown
- Guarda en `data/wiki_markdown/`

### Paso 6: UnificaciÃ³n de markdowns
- Combina todos los markdowns en un solo archivo
- Elimina secciones no relevantes (como "## Wiki Pages")
- Limpia saltos de lÃ­nea dobles
- Convierte tablas HTML a formato Markdown
- Guarda en `data/wiki_unified.md`

### Paso 7: UnificaciÃ³n de diccionarios
- Lee todos los archivos CSV de la carpeta `dicc/`
- Busca columnas que terminen en `*_ref` y `*_descr` (deben estar renombradas manualmente)
- Extrae las columnas `*_ref` y `*_descr` de cada CSV
- **OptimizaciÃ³n de tamaÃ±o**:
  - Detecta prefijos comunes en los cÃ³digos y los compacta
  - Extrae texto comÃºn de las descripciones para evitar repeticiones
  - Para `dic_lab.csv`: elimina conjunciones, determinantes y comas
- Guarda en `dicc/dictionaries_unified.md`

### Paso 8: Archivo final
- Combina `prompt.txt` + `wiki_unified.md` + `dictionaries_unified.md`
- Inserta el contenido de la wiki despuÃ©s de `### CONTEXTO ###`
- Inserta el contenido de diccionarios despuÃ©s de `### DICCIONARIOS ###`
- Guarda en `vibe_SQL_copilot.txt`

## ğŸ“ Archivos Generados

- `data/wiki_unified.md`: Markdown unificado con toda la documentaciÃ³n de la wiki
- `dicc/dictionaries_unified.md`: Diccionarios unificados y optimizados
- `vibe_SQL_copilot.txt`: Archivo final listo para usar en Copilot con estructura:
  ```
  [Contenido de prompt.txt]
  ### CONTEXTO ###
  [Contenido de wiki_unified.md]
  ### DICCIONARIOS ###
  [Contenido de dictionaries_unified.md]
  ```

## ğŸ” Funciones Principales

### `download_wiki_pages()`
Descarga pÃ¡ginas wiki desde GitLab, usando la API para obtener el contenido real.

### `download_linked_pages()`
Extrae enlaces de archivos Markdown y descarga las pÃ¡ginas referenciadas.

### `filter_useful_pages()`
Filtra pÃ¡ginas excluyendo las que estÃ¡n en `pags_descarte.txt`. Procesa todas las pÃ¡ginas disponibles excepto las listadas. La pÃ¡gina `Overview` siempre se incluye.

### `extract_text()`
Convierte HTML a Markdown preservando tablas y estructura.

### `unify_markdowns()`
Combina mÃºltiples archivos Markdown en uno solo, limpiando contenido no relevante.

### `unify_dictionaries()`
Convierte diccionarios CSV a Markdown optimizado:
- Detecta prefijos comunes en cÃ³digos (sistema de Ã¡rbol)
- Extrae texto comÃºn de descripciones para evitar repeticiones
- Aplica limpieza especial al diccionario de lab (elimina conjunciones, determinantes, comas)
- Formato compacto: `prefix:texto_comun|suffix1:diff1|suffix2:diff2|...`

### `create_final_output()`
Combina el prompt con la documentaciÃ³n unificada y los diccionarios, organizÃ¡ndolos en las secciones `### CONTEXTO ###` y `### DICCIONARIOS ###`.

## ğŸ§ª Testing

Los archivos en `test/` actÃºan como pasos individuales del pipeline y pueden ejecutarse de forma independiente para debugging o para ejecutar solo una parte del proceso.

## ğŸ“„ Licencia

Este proyecto es de uso interno para el Hospital ClÃ­nic.

## ğŸ”— Enlaces

- [Wiki de Datanex](https://gitlab.com/dsc-clinic/datascope/-/wikis/Overview)
